{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import History\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.datasets import mnist\n",
    "from keras.engine import training\n",
    "from keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from typing import Tuple, List\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Average\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from keras.applications.efficientnet_v2 import EfficientNetV2L\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import inspect\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import save\n",
    "\n",
    "\n",
    "from livelossplot.inputs.keras import PlotLossesCallback\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "from statistics import mean\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the feature matrix to a 2D array\n",
    "X_train_full = X_train_full.reshape((X_train_full.shape[0], -1))\n",
    "\n",
    "# Set the number of samples for each set\n",
    "num_train_samples = 20000\n",
    "num_val_samples = 5000\n",
    "num_test_samples = 5000\n",
    "\n",
    "# Split the dataset into a training set and the rest\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X_train_full, y_train_full, train_size=num_train_samples, random_state=42)\n",
    "\n",
    "# Split the remaining data into a validation set and a test set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=35000, random_state=42)\n",
    "\n",
    "X_test, _, y_test, _ = train_test_split(X_rest, y_rest, test_size=35000, random_state=42)\n",
    "\n",
    "# Reshape the feature matrices back to 3D arrays\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28))\n",
    "X_val = X_val.reshape((X_val.shape[0], 28, 28))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Reshape the training set feature matrix to a 4D array\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# Convert the grayscale images to 3 channels\n",
    "X_train = np.dstack([X_train] * 3)\n",
    "X_val = np.dstack([X_val] * 3)\n",
    "X_test = np.dstack([X_test] * 3)\n",
    "\n",
    "# Reshape the feature matrices back to 3D arrays\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 3))\n",
    "X_val = X_val.reshape((X_val.shape[0], 28, 28, 3))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(X_train[i])\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "input_shape = (224, 224, 3)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "n_classes= 10\n",
    "\n",
    "n_steps = X_train.shape[0] // BATCH_SIZE\n",
    "n_val_steps = X_val.shape[0] // BATCH_SIZE\n",
    "n_epochs = 100\n",
    "model_input = Input(shape=input_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the models with shallow DC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_shallow(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = VGG16(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='vgg16_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def vgg19_shallow(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = VGG19(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='vgg19_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mobilenet_shallow(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = MobileNetV2(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='mobilenet_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def xception_shallow(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = Xception(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='xception_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def resnet50_shallow(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = ResNet50(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "   \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "       \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "   \n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='resnet50_model')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def nasnetlarge_shallow(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = NASNetLarge(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "   \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "       \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "   \n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='nasnetlarge_model')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def efficientnet_shallow(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = EfficientNetV2L(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "   \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "       \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "   \n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='efficientnet_model')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "   \n",
    "   \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining models with medium FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mobilenet_medium(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = MobileNetV2(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(1024, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='mobilenet_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def xception_medium(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = Xception(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(1024, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='xception_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def vgg19_medium(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = VGG19(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(1024, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='vgg19_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def vgg16_medium(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = VGG16(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(1024, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='vgg16_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resnet50_medium(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = ResNet50(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "   \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "       \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(1024, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "   \n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='resnet50_model')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def nasnetlarge_medium(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = NASNetLarge(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "   \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "       \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(1024, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "   \n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='nasnetlarge_model')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def efficientnet_medium(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = EfficientNetV2L(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "   \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "       \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(1024, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "   \n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='efficientnet_model')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining models with DNN FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xception_dnn(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = Xception(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='xception_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def vgg19_dnn(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = VGG19(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='vgg19_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def vgg16_dnn(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = VGG16(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='vgg16_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def mobilenet_dnn(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = MobileNetV2(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='mobilenet_model')\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nasnetlarge_dnn(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = NASNetLarge(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "   \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "       \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "   \n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='nasnetlarge_model')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def resnet50_dnn(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = ResNet50(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "   \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "       \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "   \n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='resnet50_model')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def efficientnet_dnn(model_input: Tensor, optimizer) -> training.Model:\n",
    "    conv_base = EfficientNetV2L(include_top = False,\n",
    "                weights = 'imagenet',\n",
    "                input_shape = input_shape)\n",
    "   \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "       \n",
    "    top_model = Flatten()(conv_base.output)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(1000, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "   \n",
    "    model = Model(inputs = conv_base.input, outputs= output_layer, name='efficientnet_model')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the weights of trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model_shallow = vgg16_shallow(model_input, optimizer)\n",
    "vgg16_model_shallow.load_weights('tl_model_mnist_vgg16_shallow.weights.best.hdf5')\n",
    "\n",
    "vgg19_model_shallow = vgg19_shallow(model_input, optimizer)\n",
    "vgg19_model_shallow.load_weights('tl_model_mnist_vgg19_shallow.weights.best.hdf5')\n",
    "\n",
    "\n",
    "mobilenet_model_shallow = mobilenet_shallow(model_input, optimizer)\n",
    "mobilenet_model_shallow.load_weights('tl_model_mnist_mobilenet_shallow.weights.best.hdf5')\n",
    "\n",
    "xception_model_shallow = xception_shallow(model_input, optimizer)\n",
    "xception_model_shallow.load_weights('tl_model_mnist_xception_shallow.weights.best.hdf5')\n",
    "\n",
    "efficientnet_model_shallow = efficientnet_shallow(model_input, optimizer)\n",
    "efficientnet_model_shallow.load_weights('tl_model_mnist_efficientnet_shallow.weights.best.hdf5')\n",
    "\n",
    "resnet_model_shallow = resnet50_shallow(model_input, optimizer)\n",
    "resnet_model_shallow.load_weights('tl_model_mnist_resnet50_shallow.weights.best.hdf5')\n",
    "\n",
    "\n",
    "nasnetlarge_model_shallow = nasnetlarge_shallow(model_input, optimizer)\n",
    "nasnetlarge_model_shallow.load_weights('tl_model_mnist_nasnetlarge_shallow.weights.best.hdf5')\n",
    "\n",
    "\n",
    "\n",
    "####################################### medium ############################################\n",
    "\n",
    "vgg16_model_medium = vgg16_medium(model_input, optimizer)\n",
    "vgg16_model_medium.load_weights('tl_model_mnist_vgg16_medium.weights.best.hdf5')\n",
    "\n",
    "vgg19_model_medium = vgg19_medium(model_input, optimizer)\n",
    "vgg19_model_medium.load_weights('tl_model_mnist_vgg19_medium.weights.best.hdf5')\n",
    "\n",
    "\n",
    "\n",
    "mobilenet_model_medium = mobilenet_medium(model_input, optimizer)\n",
    "mobilenet_model_medium.load_weights('tl_model_mnist_mobilenet_medium.weights.best.hdf5')\n",
    "\n",
    "xception_model_medium = xception_medium(model_input, optimizer)\n",
    "xception_model_medium.load_weights('tl_model_mnist_xception_medium.weights.best.hdf5')\n",
    "\n",
    "efficientnet_model_medium = efficientnet_medium(model_input, optimizer)\n",
    "efficientnet_model_medium.load_weights('tl_model_mnist_efficientnet_medium.weights.best.hdf5')\n",
    "\n",
    "resnet_model_medium = resnet50_medium(model_input, optimizer)\n",
    "resnet_model_medium.load_weights('tl_model_mnist_resnet50_medium.weights.best.hdf5')\n",
    "\n",
    "\n",
    "nasnetlarge_model_medium = nasnetlarge_medium(model_input, optimizer)\n",
    "nasnetlarge_model_medium.load_weights('tl_model_mnist_nasnetlarge_medium.weights.best.hdf5')\n",
    "\n",
    "\n",
    "\n",
    "################################## dnn ############################\n",
    "vgg16_model_dnn = vgg16_dnn(model_input, optimizer)\n",
    "vgg16_model_dnn.load_weights('tl_model_mnist_vgg16_dnn.weights.best.hdf5')\n",
    "\n",
    "vgg19_model_dnn = vgg19_dnn(model_input, optimizer)\n",
    "vgg19_model_dnn.load_weights('tl_model_mnist_vgg19_dnn.weights.best.hdf5')\n",
    "\n",
    "\n",
    "mobilenet_model_dnn = mobilenet_dnn(model_input, optimizer)\n",
    "mobilenet_model_dnn.load_weights('tl_model_mnist_mobilenet_dnn.weights.best.hdf5')\n",
    "\n",
    "\n",
    "xception_model_dnn = xception_dnn(model_input, optimizer)\n",
    "xception_model_dnn.load_weights('tl_model_mnist_xception_dnn.weights.best.hdf5')\n",
    "\n",
    "efficientnet_model_dnn = efficientnet_dnn(model_input, optimizer)\n",
    "efficientnet_model_dnn.load_weights('tl_model_mnist_efficientnet_dnn.weights.best.hdf5')\n",
    "\n",
    "resnet_model_dnn = resnet50_dnn(model_input, optimizer)\n",
    "resnet_model_dnn.load_weights('tl_model_mnist_resnet50_dnn.weights.best.hdf5')\n",
    "\n",
    "\n",
    "nasnetlarge_model_dnn = nasnetlarge_dnn(model_input, optimizer)\n",
    "nasnetlarge_model_dnn.load_weights('tl_model_mnist_nasnetlarge_dnn.weights.best.hdf5')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class GeneticAlgorithm:\n",
    "    def __init__(self, \n",
    "                 n_genes,\n",
    "                 n_iterations,\n",
    "                 lchrom, \n",
    "                 pcross, \n",
    "                 pmutation, \n",
    "                 crossover_type, \n",
    "                 mutation_type, \n",
    "                 selection_type, \n",
    "                 cut_point,\n",
    "                 popsize, \n",
    "                 n_elites,\n",
    "                 models,\n",
    "                 n_classes,\n",
    "                 X_val,\n",
    "                 y_val,\n",
    "                 n_steps,\n",
    "                 n_val_steps,\n",
    "                 n_epochs,\n",
    "                 random_state = 123):\n",
    "        \n",
    "\n",
    "        self.n_genes = n_genes\n",
    "        self.lchrom = lchrom\n",
    "        self.popsize = popsize\n",
    "        self.pcross = pcross\n",
    "        self.pmutation = pmutation\n",
    "        self.crossover_type = crossover_type\n",
    "        self.mutation_type = mutation_type\n",
    "        self.selection_type = selection_type\n",
    "        self.random_state = random_state\n",
    "        self.n_iterations = n_iterations\n",
    "        self.n_elites = n_elites\n",
    "        self.best_fitness_evolution = []\n",
    "        self.cut_point = cut_point\n",
    "        self.models = models\n",
    "        self.n_classes = n_classes\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.batch_size = 32\n",
    "        self.input_shape = (224, 224, 3)\n",
    "        self.n_steps = n_steps\n",
    "        self.n_val_steps = n_val_steps\n",
    "        self.n_epochs = n_epochs\n",
    "    \n",
    "        pop = []\n",
    "        while (len(pop) < self.popsize):\n",
    "            chromosome = np.random.randint(2, size= self.n_genes)\n",
    "            if (sum(chromosome[:self.cut_point]) > 0 and sum(chromosome[self.cut_point:]) == 1 ):\n",
    "                pop.append(chromosome)\n",
    "\n",
    "            \n",
    "        # Convert pop to list of solutions\n",
    "        self.population = [tuple(x) for x in pop]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fitness_func(self, solution, cut_point):\n",
    "        \n",
    "        models = []\n",
    "        \n",
    "        input_shape = (224, 224, 3)\n",
    "        model_input = Input(shape=input_shape)\n",
    "        \n",
    "        # first, define the three meta learners\n",
    "        \n",
    "        for i in range(cut_point, len(solution)):\n",
    "            if (solution[i]):\n",
    "           \n",
    "                if i == 7:\n",
    "                    # 1. shallow fully connected layers\n",
    "                    for j in range(cut_point):\n",
    "                        if (solution[j]):\n",
    "                            if j == 0:\n",
    "                                models.append(vgg16_model_shallow)\n",
    "                           \n",
    "                           \n",
    "                            if j == 1:\n",
    "                                models.append(vgg19_model_shallow)\n",
    "                           \n",
    "                           \n",
    "                            if j == 2:\n",
    "                                models.append(xception_model_shallow)\n",
    "                           \n",
    "                            if j == 3:\n",
    "                                models.append(mobilenet_model_shallow)\n",
    "\n",
    "                            if j == 4:\n",
    "                                models.append(resnet_model_shallow)\n",
    "\n",
    "                            if j == 5:\n",
    "                                models.append(efficientnet_model_shallow)\n",
    "                            if j == 6:\n",
    "                                models.append(nasnetlarge_model_shallow)\n",
    "\n",
    "                           \n",
    "                           \n",
    "               \n",
    "                if i == 8:\n",
    "                   \n",
    "                    # 2. medium size fully connected layers\n",
    "                    for j in range(cut_point):\n",
    "                        if (solution[j]):\n",
    "                            if j == 0:\n",
    "                                models.append(vgg16_model_medium)\n",
    "                               \n",
    "                               \n",
    "                            if j == 1:\n",
    "                                models.append(vgg19_model_medium)\n",
    "                           \n",
    "                               \n",
    "                            if j == 2:\n",
    "                                models.append(xception_model_medium)\n",
    "                           \n",
    "                            if j == 3:\n",
    "                                models.append(mobilenet_model_medium)\n",
    "\n",
    "                            if j == 4:\n",
    "                                models.append(resnet_model_medium)\n",
    "\n",
    "                            if j == 5:\n",
    "                                models.append(efficientnet_model_medium)\n",
    "                            if j == 6:\n",
    "                                models.append(nasnetlarge_model_medium)\n",
    "\n",
    "                           \n",
    "                   \n",
    "                   \n",
    "                if i == 9:\n",
    "                    # 3. DNN FC\n",
    "                    for j in range(cut_point):\n",
    "\n",
    "                        if (solution[j]):\n",
    "\n",
    "                            if j == 0:\n",
    "                                models.append(vgg16_model_dnn)\n",
    "                                   \n",
    "                                   \n",
    "                            if j == 1:\n",
    "                                models.append(vgg19_model_dnn)\n",
    "                           \n",
    "                           \n",
    "                            if j == 2:\n",
    "                                models.append(xception_model_dnn)\n",
    "\n",
    "                            if j == 3:\n",
    "                                models.append(mobilenet_model_dnn)\n",
    "\n",
    "                            if j == 4:\n",
    "                                models.append(resnet_model_dnn)\n",
    "\n",
    "                            if j == 5:\n",
    "                                models.append(efficientnet_model_dnn)\n",
    "                            if j == 6:\n",
    "                                models.append(nasnetlarge_model_dnn)\n",
    "\n",
    "                          \n",
    "        # constructing teh ensemble of teh chromosome\n",
    "        model_input = Input(shape=(224, 224, 3))\n",
    "        model_outputs = [model(model_input) for model in models]\n",
    "        ensemble_output = Average()(model_outputs)\n",
    "        ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')\n",
    "\n",
    "        \n",
    "        optim_1 = Adam(learning_rate=0.001)\n",
    "\n",
    "        \n",
    "        # compiling the model and evaluating\n",
    "        ensemble_model.compile(optimizer=optim_1, \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "        results = ensemble_model.evaluate(X_val, y_val)\n",
    "        \n",
    "        \n",
    "        return results[1]\n",
    "\n",
    "\n",
    "    def get_fitness_scores(self):\n",
    "        scores = [self.fitness_func(sol, self.cut_point) for sol in self.population]\n",
    "        return np.array(scores)\n",
    "\n",
    "    def __append_best_score(self, scores):\n",
    "        best_score = np.max(scores)\n",
    "        self.best_fitness_evolution.append(best_score)\n",
    "        return 'Ok'\n",
    "    \n",
    "    def __ranking_selection(self, scores):\n",
    "        ind = np.argsort(scores)\n",
    "\n",
    "        s = sum(ind)\n",
    "        t = np.random.rand() * s\n",
    "        partial_sum = 0\n",
    "        i=0\n",
    "        while(partial_sum <t and i <len(scores)):\n",
    "            partial_sum += scores[i]\n",
    "\n",
    "        selected = i\n",
    "        return selected \n",
    "    \n",
    "    def __roulette_selection(self, scores):\n",
    "        s = sum(scores)\n",
    "        t = np.random.rand() * s\n",
    "        partial_sum = 0\n",
    "        i=0\n",
    "        while(partial_sum <t and i <len(scores)):\n",
    "            partial_sum += scores[i]\n",
    "\n",
    "        selected = i\n",
    "        return selected\n",
    "\n",
    "    def select(self, scores, selection_type):\n",
    "\n",
    "        if selection_type not in ['ranking', 'roulette']:\n",
    "            raise ValueError('Type should be ranking or tournament')\n",
    "\n",
    "        if selection_type == 'ranking':\n",
    "            ind = self.__ranking_selection(scores)\n",
    "        elif selection_type == 'roulette':\n",
    "            ind = self.__roulette_selection(scores)\n",
    "        else:\n",
    "            pass\n",
    "        return ind\n",
    "\n",
    "    def flip(self, p):\n",
    "        return 1 if np.random.rand() < p else 0\n",
    "    \n",
    "    def format_func(self, value):\n",
    "        return \"%.3f\" % value\n",
    "\n",
    "    def __crossover(self, \n",
    "                    parent1, \n",
    "                    parent2, \n",
    "                    crossover_type,\n",
    "                    pcross,\n",
    "                    lchrom,\n",
    "                    mutation_type,\n",
    "                    pmutation):\n",
    "        \n",
    "        if crossover_type not in ['uniform', 'one_point', 'two_point']:\n",
    "                raise ValueError('crossover_type should be one of uniform, one_point or multi_point')\n",
    "\n",
    "            \n",
    "        if self.flip(pcross):\n",
    "            \n",
    "            if crossover_type == 'one_point':\n",
    "                index = np.random.choice(range(1, lchrom)) \n",
    "\n",
    "                parent1 = list(parent1)\n",
    "                parent2 = list(parent2)\n",
    "\n",
    "                child1 = self.__mutation(parent1[:index] + parent2[index:], mutation_type, pmutation)\n",
    "                child2 = self.__mutation(parent2[:index] + parent1[index:] , mutation_type, pmutation)\n",
    "                children = [child1, child2]\n",
    "            elif crossover_type == 'two_point':\n",
    "                point1 = np.random.choice(range(1, lchrom)) \n",
    "                point2 = np.random.choice(point1, range(lchrom))\n",
    "                child1 = self.__mutation(parent1[:point1] + parent2[point1: point2] + parent1[point2:], mutation_type, pmutation)\n",
    "                child2 = self.__mutation(parent2[:point1] + parent1[point1: point2] + parent2[point2:], mutation_type, pmutation)\n",
    "                children = [child1, child2]\n",
    "            else:\n",
    "                t = np.random.rand()\n",
    "                temp = np.random.rand(lchrom)\n",
    "                child1 = self.__mutation([parent1[i] if temp[i] > t else parent2[i] for i in range(len(temp)) ], mutation_type, pmutation)\n",
    "                child2 = self.__mutation([parent2[i] if temp[i] > t else parent1[i] for i in range(len(temp)) ], mutation_type, pmutation)\n",
    "                children = [child1, child2]\n",
    "               \n",
    "        else:\n",
    "            \n",
    "            child1 = self.__mutation(parent1, self.mutation_type, pmutation)\n",
    "            child2 = self.__mutation(parent2, self.mutation_type, pmutation)\n",
    "            children = [child1, child2]\n",
    "        \n",
    "        return children\n",
    "    \n",
    "\n",
    "\n",
    "    def __mutation(self, individual, mutation_type, pmutation):\n",
    "\n",
    "        if mutation_type not in ['bitstring', 'inversion', 'swap']:\n",
    "            raise ValueError('mutation_type should be one of bitstring or inversion or swap')\n",
    "\n",
    "\n",
    "        index = np.random.choice(len(individual))\n",
    "        index2 = np.random.choice(len(individual))\n",
    "        \n",
    "        # Convert individual to list so that can be modified\n",
    "        individual_mod = list(individual)\n",
    "        if (self.flip(pmutation)):\n",
    "            \n",
    "            if mutation_type == 'bitstring':\n",
    "                individual_mod[index] = 1 - individual_mod[index]\n",
    "            elif mutation_type == 'inversion':\n",
    "                individual_mod= individual_mod[0:index] + individual_mod[index2:index-1:-1] + individual_mod[index2+1:]\n",
    "            else:\n",
    "                individual_mod[index], individual_mod[index2] = individual_mod[index2], individual_mod[index]\n",
    "        else:\n",
    "            \n",
    "            pass\n",
    "        \n",
    "        individual = tuple(individual_mod)\n",
    "\n",
    "        return individual\n",
    "\n",
    "    def optimize(self):\n",
    "\n",
    "        for i in tqdm(range(self.n_iterations)):\n",
    "            print(\"iteration number:\" , i+1)\n",
    "\n",
    "            # calculate fitness score\n",
    "            scores = self.get_fitness_scores()\n",
    "            #storing scores\n",
    "            scores_array = [self.format_func(score) for score in scores]\n",
    "            sfile = open(\"scores.txt\", \"a\")\n",
    "            sfile.write(str(scores_array))\n",
    "            sfile.write(\"\\n\")\n",
    "            sfile.close()\n",
    "            \n",
    "            # append best score\n",
    "            _ = self.__append_best_score(scores)\n",
    "\n",
    "            # get the result wher he results is the best\n",
    "            best_score_ind = scores.tolist().index(max(scores))\n",
    "\n",
    "            best_solution = self.population[best_score_ind]\n",
    "            # storing best solution\n",
    "            solutionfile = open(\"best_solution.txt\", \"a\")\n",
    "            content = str(best_solution)\n",
    "            solutionfile.write(content)\n",
    "            solutionfile.write(\"\\n\")\n",
    "            solutionfile.close()\n",
    "            print(best_solution)\n",
    "\n",
    "\n",
    "\n",
    "            best_fitness = np.array(self.best_fitness_evolution)\n",
    "            # increasing teh mutation rate if the GA is stuck for five consecutive iterations\n",
    "            if (i>=5):\n",
    "                if (best_fitness[i-1] == best_fitness[i-2]) and (best_fitness[i-2] == best_fitness[i-3]) \\\n",
    "                and (best_fitness[i-3] == best_fitness[i-4]) and (best_fitness[i-4] == best_fitness[i-5]):\n",
    "                    self.pmutation =  self.pmutation + 0.05\n",
    "\n",
    "            fitfile = open(\"fitness_evolution.txt\", \"a\")\n",
    "            fit = str(best_fitness)\n",
    "            fitfile.write(fit)\n",
    "            fitfile.write(\"\\n\")\n",
    "            fitfile.close()\n",
    "            print(best_fitness)\n",
    "            \n",
    "            # choose the elites of the current population\n",
    "            ind = np.argsort(scores)\n",
    "        \n",
    "            elites = [self.population[i] for i in ind[-self.n_elites:]]\n",
    "\n",
    "            #append the elites to the population\n",
    "            new_population = [tuple(elite) for elite in elites]\n",
    "\n",
    "            # make selection\n",
    "            #new_population = []\n",
    "            j = self.n_elites\n",
    "            while j < self.popsize:\n",
    "                \n",
    "                # select parents from population\n",
    "                mate1 = self.select(scores, self.selection_type)\n",
    "                mate2 = self.select(scores, self.selection_type)\n",
    "\n",
    "                mate1 = tuple(self.population[mate1])\n",
    "                mate2 = tuple(self.population[mate2])\n",
    "\n",
    "                #crossover + mutation\n",
    "                children = self.__crossover(mate1, mate2, self.crossover_type, self.pcross, self.lchrom,self.mutation_type, self.pmutation)\n",
    "                children = [tuple(child) for child in children]\n",
    "                \n",
    "                \n",
    "                \n",
    "                if ((sum(children[0][:self.cut_point]) != 0 and sum(children[0][self.cut_point:]) == 1) and\n",
    "                    sum(children[1][:self.cut_point]) != 0 and sum(children[1][self.cut_point:]) == 1):\n",
    "                    \n",
    "                    new_population.append(tuple(children[0]))\n",
    "                    new_population.append(tuple(children[1]))\n",
    "                    j+=2\n",
    "                \n",
    "                \n",
    "\n",
    "            self.population = new_population\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        return (best_solution, self.best_fitness_evolution[-1])\n",
    "\n",
    "\n",
    "    # run the genetic algorithm\n",
    "    def view_fitness_evolution(self):\n",
    "        plt.plot(\n",
    "            range(len(self.best_fitness_evolution)),\n",
    "            self.best_fitness_evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"vgg16\", \"VGG19\",\n",
    "          \"ResNet50\",\"DenseNet201\"]\n",
    "ga = GeneticAlgorithm(\n",
    "    n_genes =10,\n",
    "    n_iterations = 100,\n",
    "    lchrom = 10, \n",
    "    cut_point = 7, \n",
    "    pcross = 0.8, \n",
    "    pmutation = 0.2, \n",
    "    crossover_type = 'one_point', \n",
    "    mutation_type = 'bitstring', \n",
    "    selection_type = 'ranking', \n",
    "    popsize = 7, \n",
    "    n_elites = 1,\n",
    "    models = models,\n",
    "    n_classes = n_classes,\n",
    "    n_epochs=n_epochs,\n",
    "    n_steps=n_steps,\n",
    "    n_val_steps=n_val_steps,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    random_state = 123\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ga.optimize())\n",
    "ga.view_fitness_evolution()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models1 = [vgg16_model_dnn, efficientnet_model_dnn, resnet_model_dnn, nasnetlarge_model_dnn]\n",
    "model_input = Input(shape=(224, 224, 3))\n",
    "model_outputs = [model(model_input) for model in models1]\n",
    "ensemble_output = Average()(model_outputs)\n",
    "ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')\n",
    "plot_loss_densenet = PlotLossesCallback()\n",
    "\n",
    "optim_1 = Adam(learning_rate=0.001)\n",
    "\n",
    "tl_checkpoint_ensemble1 = ModelCheckpoint(filepath='tl_model_processed_ensemble1.weights.best.hdf5',\n",
    "                                      monitor='loss',\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True,\n",
    "                                verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='loss',\n",
    "                        patience=10,\n",
    "                        restore_best_weights=True,\n",
    "                        mode='min')\n",
    "\n",
    "ensemble_model.compile(optimizer=optim_1, \n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "ensemble_model.fit(X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs= n_epochs,\n",
    "        shuffle= True,\n",
    "        steps_per_epoch=n_steps,\n",
    "        callbacks=[tl_checkpoint_ensemble1, early_stop, plot_loss_densenet],\n",
    "        verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = ensemble_model.predict(X_test)\n",
    "y_pred = y_prob.argmax(axis=-1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, jaccard_score, roc_auc_score\n",
    "\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "balanced_acc = balanced_accuracy_score(y_pred, y_test)\n",
    "\n",
    "#auc = roc_auc_score(y_score = y_pred, y_true = y_test, multi_class=\"ovr\")\n",
    "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "def sensitivity(y_true,y_pred):\n",
    "        cm=confusion_matrix(y_true, y_pred)\n",
    "        FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "        FN = cm.sum(axis=1) - np.diag(cm)\n",
    "        TP = np.diag(cm)\n",
    "        TN = cm.sum() - (FP + FN + TP)\n",
    "        Sensitivity = TP/(TP+FN)    \n",
    "        return np.mean(Sensitivity)\n",
    "\n",
    "sens = sensitivity(y_test, y_pred)\n",
    "def specificity(y_true,y_pred):\n",
    "        cm=confusion_matrix(y_true, y_pred)\n",
    "        FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "        FN = cm.sum(axis=1) - np.diag(cm)\n",
    "        TP = np.diag(cm)\n",
    "        TN = cm.sum() - (FP + FN + TP)\n",
    "        Specificity = TN/(TN+FP)    \n",
    "        return np.mean(Specificity)\n",
    "specif= specificity(y_test, y_pred)\n",
    "\n",
    "f1 = 2 * (precision * sens) / (precision + sens)\n",
    "\n",
    "import math\n",
    "g_mean = math.sqrt(sens * specif)\n",
    "\n",
    "data = {\n",
    "    \"accuracy\" : acc,\n",
    "    \"balanced_acc\" : balanced_acc,\n",
    "    \"precision\": precision,\n",
    "    \"f1\": f1,\n",
    "    \"sensitivity\": sens,\n",
    "    \"specificity\": specif,\n",
    "    \"g_mean\": g_mean\n",
    "}\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
